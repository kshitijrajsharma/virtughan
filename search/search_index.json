{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"VirtuGhan","text":"<p>Name is combination of two words <code>virtual</code> &amp; <code>cube</code> , where <code>cube</code> translated to Nepali word <code>\u0918\u0928</code>,  also known as virtual computation cube. You can test demo of this project for Sentinel2 data at : https://virtughan.live/ </p>"},{"location":"#install","title":"Install","text":"<p>As a python package : </p> <p>https://pypi.org/project/VirtuGhan/ </p> <pre><code>pip install VirtuGhan\n</code></pre>"},{"location":"#basic-usage","title":"Basic Usage","text":"<p>Follow Notebook Here</p>"},{"location":"#background","title":"Background","text":"<p>We started initially by looking at how Google Earth Engine (GEE) computes results on-the-fly at different zoom levels on large-scale Earth observation datasets. We were fascinated by the approach and felt an urge to replicate something similar on our own in an open-source manner. We knew Google uses their own kind of tiling, so we started from there.</p> <p>Initially, we faced a challenge \u2013 how could we generate tiles and compute at the same time without pre-computing the whole dataset? Pre-computation would lead to larger processed data sizes, which we didn\u2019t want. And so, the exploration began and the concept of on the fly tiling computation introduced </p> <p>At university, we were introduced to the concept of data cubes and the advantages of having a time dimension and semantic layers in the data. It seemed fascinating, despite the challenge of maintaining terabytes of satellite imagery. We thought \u2013 maybe we could achieve something similar by developing an approach where one doesn\u2019t need to replicate data but can still build a data cube with semantic layers and computation. This raised another challenge \u2013 how to make it work? And hence come the virtual data cube</p> <p>We started converting Sentinel-2 images to Cloud Optimized GeoTIFFs (COGs) and experimented with the time dimension using Python\u2019s xarray to compute the data. We found that earth-search\u2019s effort to store Sentinel images as COGs made it easier for us to build virtual data cubes across the world without storing any data. This felt like an achievement and proof that modern data cubes should focus on improving computation rather than worrying about how to manage terabytes of data.</p> <p>We wanted to build something to show that this approach actually works and is scalable. We deliberately chose to use only our laptops to run the prototype and process a year\u2019s worth of data without expensive servers.</p> <p>Learn about COG and how to generate one for this project Here</p>"},{"location":"#purpose","title":"Purpose","text":""},{"location":"#1-efficient-on-the-fly-tile-computation","title":"1. Efficient On-the-Fly Tile Computation","text":"<p>This research explores how to perform real-time calculations on satellite images at different zoom levels, similar to Google Earth Engine, but using open-source tools. By using Cloud Optimized GeoTIFFs (COGs) with Sentinel-2 imagery, large images can be analyzed without needing to pre-process or store them. The study highlights how this method can scale well and work efficiently, even with limited hardware. Our main focus is on how to scale the computation on different zoom-levels without introducing server overhead </p> <p>Watch</p>"},{"location":"#example-python-usage","title":"Example python usage","text":"<pre><code>import mercantile\nfrom PIL import Image\nfrom io import BytesIO\nfrom vcube.tile import TileProcessor\n\nlat, lon = 28.28139, 83.91866\nzoom_level = 12\nx, y, z = mercantile.tile(lon, lat, zoom_level)\n\ntile_processor = TileProcessor()\n\nimage_bytes, feature = await tile_processor.cached_generate_tile(\n    x=x,\n    y=y,\n    z=z,\n    start_date=\"2020-01-01\",\n    end_date=\"2025-01-01\",\n    cloud_cover=30,\n    band1=\"red\",\n    band2=\"nir\",\n    formula=\"(band2-band1)/(band2+band1)\",\n    colormap_str=\"RdYlGn\",\n)\n\nimage = Image.open(BytesIO(image_bytes))\n\nprint(f\"Tile: {x}_{y}_{z}\")\nprint(f\"Date: {feature['properties']['datetime']}\")\nprint(f\"Cloud Cover: {feature['properties']['eo:cloud_cover']}%\")\n\nimage.save(f'tile_{x}_{y}_{z}.png')\n</code></pre>"},{"location":"#2-virtual-computation-cubes-focusing-on-computation","title":"2. Virtual Computation Cubes: Focusing on Computation","text":"<p>While storing large images can offer some benefits, we believe that placing emphasis on efficient computation yields far greater advantages and effectively removes the need to worry about large-scale image storage. COGs make it possible to analyze images directly without storing the entire dataset. This introduces the idea of virtual computation cubes, where images are stacked and processed over time, allowing for analysis across different layers ( including semantic layers ) without needing to download or save everything. So original data is never replicated. In this setup, a data provider can store and convert images to COGs, while users or service providers focus on calculations. This approach reduces the need for terra-bytes of storage and makes it easier to process large datasets quickly.</p>"},{"location":"#example-python-usage_1","title":"Example python usage","text":"<p>Example NDVI calculation </p> <pre><code>from vcube.engine import VCubeProcessor\n\nprocessor = VCubeProcessor(\n    bbox=[83.84765625, 28.22697003891833, 83.935546875, 28.304380682962773],\n    start_date=\"2023-01-01\",\n    end_date=\"2025-01-01\",\n    cloud_cover=30,\n    formula=\"(band2-band1)/(band2+band1)\",\n    band1=\"red\",\n    band2=\"nir\",\n    operation=\"median\",\n    timeseries=True,\n    output_dir=\"virtughan_output\",\n    workers=16\n)\n\nprocessor.compute()\n</code></pre>"},{"location":"#summary","title":"Summary","text":"<p>This research introduces methods on how to use COGs, the SpatioTemporal Asset Catalog (STAC) API, and NumPy arrays to improve the way large Earth observation datasets are accessed and processed. The method allows users to focus on specific areas of interest, process data across different bands and layers over time, and maintain optimal resolution while ensuring fast performance. By using the STAC API, it becomes easier to search for and only process the necessary data without needing to download entire images ( not even the single scene , only accessing the parts ) The study shows how COGs can improve the handling of large datasets, not only making  the access faster but also making computation efficient, and scalable across different zoom levels . </p> <p></p>"},{"location":"#sample-case-study","title":"Sample case study :","text":"<p>Watch Video</p>"},{"location":"#local-setup","title":"Local Setup","text":"<p>This project has FASTAPI and Plain JS Frontend.</p> <p>Inorder to setup project , follow here</p>"},{"location":"#tech-stack","title":"Tech Stack","text":""},{"location":"#resources-and-credits","title":"Resources and Credits","text":"<ul> <li>https://registry.opendata.aws/sentinel-2-l2a-cogs/ COGS Stac API for sentinel-2</li> </ul>"},{"location":"#contribute","title":"Contribute","text":"<p>Liked the concept? Want to be part of it ?  </p> <p>If you have experience with JavaScript, FastAPI, building geospatial Python libraries , we\u2019d love your contributions! But you don\u2019t have to be a coder to help\u2014spreading the word is just as valuable.  </p>"},{"location":"#how-you-can-contribute","title":"How You Can Contribute ?","text":"<p>\u2705 Code Contributions - Fork the repository and submit a PR with improvements, bug fixes, or features. Use commitizen for your commits - Help us refine our development guidelines !  </p> <p>\u2705 Documentation &amp; Testing - Improve our docs to make it easier for others to get started. - Test features and report issues to help us build a robust system.  </p> <p>\u2705 Spread the Word - Share the project on social media or among developer communities. - Bring in more contributors who might be interested!  </p> <p>\ud83d\udc99 Support Us If you love what we\u2019re building, consider buying us a coffee \u2615 to keep the project going!  </p> <p> </p>"},{"location":"#acknowledgment","title":"Acknowledgment","text":"<p>This project was initiated during the project work of our master's program , Coopernicus Masters in Digital Earth.  We are thankful to all those involved and supported us from the program. </p> <p> </p>"},{"location":"#copyright","title":"Copyright","text":"<p>\u00a9 2024 \u2013 Concept by Kshitij and Upen , Distributed under GNU General Public License v3.0 </p>"},{"location":"cog/","title":"Understanding COG","text":""},{"location":"cog/#understand-cog","title":"Understand COG","text":""},{"location":"cog/#cloud-optimized-geotiff-cog","title":"Cloud Optimized GeoTIFF (COG)","text":"<p>A Cloud Optimized GeoTIFF (COG) is a GeoTIFF file that has been optimized for efficient access and processing in cloud environments. It allows for efficient reading of small portions of the file without requiring the entire file to be downloaded, making it ideal for use in web applications and cloud-based geographic information systems (GIS).</p>"},{"location":"cog/#key-features-of-cog","title":"Key Features of COG","text":"<ol> <li> <p>Internal Tiling: The image data is divided into regular tiles, typically 256x256 pixels. This tiling allows for efficient access to small parts of the image, which is particularly useful for operations like map tiling and zooming.</p> </li> <li> <p>Overviews (Pyramids): These are reduced resolution versions of the image that allow for faster access at different zoom levels. Overviews are stored within the same file and can be accessed quickly to display lower resolution images when high resolution is not necessary.</p> </li> <li> <p>Efficient Data Access: COGs are structured to allow HTTP range requests, enabling clients to request just the portions of the file they need. This makes it possible to read a small part of the image without downloading the entire file.</p> </li> <li> <p>Metadata: COGs include metadata that describes the internal tiling and overviews, enabling clients to efficiently locate and access the required data.</p> </li> </ol>"},{"location":"cog/#how-cog-works-internally","title":"How COG Works Internally","text":""},{"location":"cog/#1-internal-tiling","title":"1. Internal Tiling","text":"<ul> <li> <p>Tiles: The image is divided into regular, non-overlapping tiles (e.g., 256x256 pixels). Each tile can be accessed independently, allowing for efficient read operations on small portions of the image.</p> </li> <li> <p>Tile Indexing: The tiles are indexed within the file, allowing for quick location and retrieval of specific tiles.</p> </li> </ul>"},{"location":"cog/#2-overviews-pyramids","title":"2. Overviews (Pyramids)","text":"<ul> <li> <p>Purpose: Overviews provide lower resolution versions of the image. They are used to quickly access and display the image at different zoom levels without processing the full-resolution data.</p> </li> <li> <p>Levels: Overviews are created at multiple levels of reduced resolution. For example, a 1:4 overview would represent the image at one-fourth the resolution of the original.</p> </li> <li> <p>Storage: Overviews are stored within the same GeoTIFF file and can be accessed through the same indexing mechanism as the full-resolution tiles.</p> </li> </ul>"},{"location":"cog/#3-efficient-data-access","title":"3. Efficient Data Access","text":"<ul> <li> <p>HTTP Range Requests: COGs support HTTP range requests, which allow clients to request specific byte ranges from the file. This is particularly useful for accessing individual tiles or overviews without downloading the entire file.</p> </li> <li> <p>Indexing Metadata: Metadata within the COG provides information about the structure of the file, including the location of tiles and overviews. This metadata is used by clients to efficiently locate and read the required data.</p> </li> </ul>"},{"location":"cog/#tiling-and-overview-example","title":"Tiling and Overview Example","text":"<p>Consider an example where we have a high-resolution satellite image stored as a COG:</p> <ul> <li>High-Resolution Image: The original image is 10,000 x 10,000 pixels.</li> <li>Tiles: The image is divided into 256x256 pixel tiles.</li> <li>Overviews: Overviews are created at multiple levels (e.g., 1:2, 1:4, 1:8).</li> </ul> <p>When a client requests a view of the image at a low zoom level, the client can: 1. Access Overviews: Fetch the appropriate overview level (e.g., 1:8) to quickly display a low-resolution version of the image. 2. Access Tiles: Request specific tiles from the full-resolution image as needed for detailed views.</p>"},{"location":"cog/#benefits-of-cog","title":"Benefits of COG","text":"<ul> <li>Performance: Faster data access and reduced bandwidth usage due to efficient tile and overview retrieval.</li> <li>Scalability: Ideal for cloud environments where data is accessed over the network.</li> <li>Flexibility: Supports a wide range of applications, from web mapping to scientific analysis.</li> </ul>"},{"location":"cog/#how-to-generate-cog-for-this-project","title":"How to Generate  COG for this project ?","text":"<p>Sentinel 2 Raw Image  </p> <p>Work on 10m resolution </p> <p>Get all the jp2 images </p> <pre><code>ls -1 *.jp2 &gt; jp2_list.txt\n</code></pre> <p>Merge</p> <pre><code>gdal_merge.py -separate --optfile jp2_list.txt -o sentinel_r10.tif \n</code></pre> <p>Or</p> <pre><code>gdal_merge.py -separate T45RTM_20241225T050129_B02_10m.jp2 T45RTM_20241225T050129_B03_10m.jp2 T45RTM_20241225T050129_B04_10m.jp2 T45RTM_20241225T050129_B08_10m.jp2 -o sentinel210m.tif -a_nodata 0\n</code></pre> <p>Check :  <pre><code>gdalinfo sentinel_r10.tif\n</code></pre></p> <p></p> <p>Size : </p> <p>2.1 GB for the merged file </p> <p>Conversion to COG : </p> <pre><code>gdal_translate -of COG sentinel_r10.tif sentinel_r10_cog.tif  -co NUM_THREADS=32 -co COMPRESS=DEFLATE -co BIGTIFF=YES -co TILING_SCHEME=GoogleMapsCompatible -co LEVEL=9\n</code></pre> <p>GDAL info</p> <p><pre><code> gdalinfo sentinel_r10_cog.tif\n</code></pre> </p>"},{"location":"docs/","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"docs/#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"docs/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"install/","title":"Installation","text":""},{"location":"install/#installation-and-setup","title":"Installation and Setup","text":""},{"location":"install/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or higher</li> <li>poetry </li> </ul>"},{"location":"install/#install-poetry","title":"Install Poetry","text":"<p>If you don't have poetry installed, you can install it using the following command:</p> <pre><code>pip install poetry\n</code></pre>"},{"location":"install/#install","title":"Install","text":"<pre><code>poetry install\n</code></pre>"},{"location":"install/#run","title":"Run","text":"<pre><code>poetry run uvicorn API:app --reload --workers 2\n</code></pre>"}]}